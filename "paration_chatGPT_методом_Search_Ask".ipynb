{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlhFAOYfhI5a"
      },
      "source": [
        "# Сбор данных и фрагментация\n",
        "**Оставлю из урока так как есть, что бы помнить**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P-w02hASPVZ"
      },
      "source": [
        "Для сбора и подготовки данных нам необходимо:\n",
        "* Собрать все заголовки статей заданной категории статей Википедии, заходя на первый уровень вложенности статей.\n",
        "* Разделить каждую статью на разделы (секции) и подразделы. Отбросить менее релевантные разделы, такие как внешние ссылки и сноски.\n",
        "* Очистить текст, удалив теги ссылок, пробелы и очень короткие секции (разделы).\n",
        "* Добавить заголовки и подзаголовки к тексту каждого раздела, чтобы помочь chatGPT понять контекст."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52qZgnP0SoCX"
      },
      "source": [
        "### Сбор заголовков статей из категории"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmFaPCEN6FWl"
      },
      "outputs": [],
      "source": [
        "# Отключим предупреждения в колабе. Будет меньше лишней информации в выводе\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-vj319smw67_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b400c7af-a8f4-4ee2-95fb-67e3703ec823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/251.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# installing libraries\n",
        "!pip install openai mwclient mwparserfromhell tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsD_cLZsxehi"
      },
      "outputs": [],
      "source": [
        "# imports libraries\n",
        "import mwclient  # библиотека для работы с MediaWiki API для загрузки примеров статей Википедии\n",
        "import mwparserfromhell  # Парсер для MediaWiki\n",
        "import openai  # будем использовать для токинизации\n",
        "import pandas as pd  # В DataFrame будем хранить базу знаний и результат токинизации базы знаний\n",
        "import re  # для вырезания ссылок <ref> из статей Википедии\n",
        "import tiktoken  # для подсчета токенов\n",
        "import time  # Импортируем модуль time для задеркжи парсера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Buz_MZYIoN"
      },
      "source": [
        "# Делаю под русско-язычную Википедию\n",
        "*Добавлю проверку на существующую страницу и обработку исключений и ошибок try-except*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYPCIHcxxm5F",
        "outputId": "dc86c7df-e578-4389-8c5d-c9648b28276d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Собрано 155 заголовков статей в категории 'Медицина'.\n"
          ]
        }
      ],
      "source": [
        "# parsing\n",
        "# Задаём категорию и сайт русской Википедии\n",
        "CATEGORY_TITLE = \"Медицина\"  # Указываем здесь без слова Категория - Category\n",
        "WIKI_SITE = \"ru.wikipedia.org\"\n",
        "\n",
        "# Подключаемся к русской версии Википедии\n",
        "site = mwclient.Site(WIKI_SITE)\n",
        "\n",
        "# Убедимся, что страница действительно существует на русском языке.\n",
        "category_page = site.categories[CATEGORY_TITLE]\n",
        "if not category_page.exists:\n",
        "    raise ValueError(f\"Категория '{CATEGORY_TITLE}' не найдена.\")\n",
        "\n",
        "# Функция сбора заголовков всех статей в указанной категории и её подкатегориях\n",
        "def titles_from_category(\n",
        "    category: mwclient.listing.Category,  # Задаем типизированный параметр категории статей\n",
        "    max_depth: int  # Определяем глубину вложения статей\n",
        ") -> set[str]:\n",
        "    \"\"\"\n",
        "    Возвращает множество заголовков страниц в данной категории Википедии и её подкатегориях.\n",
        "\n",
        "    :param category: Объект категории из библиотеки mwclient\n",
        "    :param max_depth: Максимальное количество уровней вложенности категорий\n",
        "    :return: Множество заголовков статей\n",
        "    \"\"\"\n",
        "    titles = set()  # Используем множество для хранения заголовков статей\n",
        "    for item in category.members():\n",
        "        if isinstance(item, mwclient.page.Page):\n",
        "            try:\n",
        "                # Попытка получить текст страницы\n",
        "                text = item.text()\n",
        "                # Добавляем название страницы в множество заголовков\n",
        "                titles.add(item.name)\n",
        "                # Добавляем задержку в 1 секунду между запросами\n",
        "                time.sleep(1)\n",
        "            except Exception as e:\n",
        "                print(f\"Произошла ошибка при получении текста страницы '{item.name}': {e}\")\n",
        "        elif isinstance(item, mwclient.listing.Category) and max_depth > 0:\n",
        "            # Рекурсивно обрабатываем подкатегорию\n",
        "            deeper_titles = titles_from_category(item, max_depth=max_depth - 1)\n",
        "            titles.update(deeper_titles)\n",
        "    return titles\n",
        "\n",
        "# Собираем заголовки статей из данной категории и одного уровня вложенных подкатегорий\n",
        "titles = titles_from_category(category_page, max_depth=1)\n",
        "\n",
        "# Печать результата\n",
        "print(f\"Собрано {len(titles)} заголовков статей в категории '{CATEGORY_TITLE}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnZQNAmWRZtl"
      },
      "source": [
        "### Извлечение секций из документов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G10Fuk-QtIc"
      },
      "source": [
        "Определим секции в документах, которые менее релевантны и их можно отбросить:\n",
        "Так как использую русско-язычную версию Википедии, нужно и отображать секции на русском языке\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TVbIHz9RSGi"
      },
      "outputs": [],
      "source": [
        "# section_ejection\n",
        "# Задаем секции, которые будут отброшены при парсинге статей\n",
        "SECTIONS_TO_IGNORE = [\n",
        "    \"See also\",\n",
        "    \"References\",\n",
        "    \"External links\",\n",
        "    \"Further reading\",\n",
        "    \"Footnotes\",\n",
        "    \"Bibliography\",\n",
        "    \"Sources\",\n",
        "    \"Citations\",\n",
        "    \"Literature\",\n",
        "    \"Footnotes\",\n",
        "    \"Notes and references\",\n",
        "    \"Photo gallery\",\n",
        "    \"Works cited\",\n",
        "    \"Photos\",\n",
        "    \"Gallery\",\n",
        "    \"Notes\",\n",
        "    \"References and sources\",\n",
        "    \"References and notes\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFvTzEVbZIk"
      },
      "source": [
        "Код зависит от правильной обработки русского текста. Я использую библиотеку mwparserfromhell, которая отлично справляется с разбором структуры страниц Википедии независимо от языка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVL7yHeex2nO"
      },
      "outputs": [],
      "source": [
        "# ettings_functions\n",
        "# Функция возвращает список всех вложенных секций для заданной секции страницы Википедии\n",
        "def all_subsections_from_section(\n",
        "    section: mwparserfromhell.wikicode.Wikicode,  # Объект секции, который нужно обработать\n",
        "    parent_titles: list[str],  # Список родительских заголовков\n",
        "    sections_to_ignore: set[str],  # Набор заголовков секций, которые нужно игнорировать\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из раздела Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "    # Извлекаем заголовки из секции\n",
        "    headings = [str(h) for h in section.filter_headings()]\n",
        "    # Получаем заголовок текущей секции\n",
        "    title = headings[0].strip(\"=\" + \" \")\n",
        "\n",
        "    # Если заголовок в списке игнорируемых, возвращаем пустой список\n",
        "    if title in sections_to_ignore:\n",
        "        return []\n",
        "\n",
        "    # Обновляем список заголовков, добавляя текущий\n",
        "    titles = parent_titles + [title]\n",
        "    # Получаем полный текст секции\n",
        "    full_text = str(section)\n",
        "    # Извлекаем текст текущей секции, исключая заголовок\n",
        "    section_text = full_text.split(title)[1]\n",
        "\n",
        "    # Если в секции только один заголовок, возвращаем его текст\n",
        "    if len(headings) == 1:\n",
        "        return [(titles, section_text)]\n",
        "    else:\n",
        "        # Иначе, находим первый подзаголовок\n",
        "        first_subtitle = headings[1]\n",
        "        # Извлекаем текст до первого подзаголовка\n",
        "        section_text = section_text.split(first_subtitle)[0]\n",
        "        # Добавляем текущую секцию в результаты\n",
        "        results = [(titles, section_text)]\n",
        "        # Рекурсивно обрабатываем все вложенные секции\n",
        "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
        "            results.extend(all_subsections_from_section(subsection, titles, sections_to_ignore))\n",
        "        return results\n",
        "\n",
        "\n",
        "# Функция возвращает список всех секций страницы, за исключением тех, которые отбрасываем\n",
        "def all_subsections_from_title(\n",
        "    title: str,  # Заголовок страницы Википедии\n",
        "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE,  # Набор заголовков секций, которые нужно игнорировать\n",
        "    site_name: str = WIKI_SITE,  # Имя сайта Википедии\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из заголовка страницы Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "    # Подключаемся к сайту Википедии\n",
        "    site = mwclient.Site(site_name)\n",
        "    # Получаем страницу по заголовку\n",
        "    page = site.pages[title]\n",
        "\n",
        "    # Если страница не существует, выбрасываем исключение\n",
        "    if not page.exists:\n",
        "        raise ValueError(f\"Страница '{title}' не найдена.\")\n",
        "\n",
        "    # Получаем текст страницы\n",
        "    text = page.text()\n",
        "    # Парсим текст страницы\n",
        "    parsed_text = mwparserfromhell.parse(text)\n",
        "    # Извлекаем заголовки из текста\n",
        "    headings = [str(h) for h in parsed_text.filter_headings()]\n",
        "\n",
        "    # Если есть заголовки, извлекаем текст до первого заголовка\n",
        "    if headings:\n",
        "        summary_text = str(parsed_text).split(headings[0])[0]\n",
        "    else:\n",
        "        # Если заголовков нет, весь текст является аннотацией\n",
        "        summary_text = str(parsed_text)\n",
        "\n",
        "    # Добавляем аннотацию страницы в результаты\n",
        "    results = [([title], summary_text)]\n",
        "    # Обрабатываем все секции уровня 2\n",
        "    for subsection in parsed_text.get_sections(levels=[2]):\n",
        "        results.extend(all_subsections_from_section(subsection, [title], sections_to_ignore))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbUDCg3bx_h2",
        "outputId": "01fdf94d-cf8e-4658-c1d2-59d1b4009eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено 978 секций на 155 страницах\n"
          ]
        }
      ],
      "source": [
        "#into_sections\n",
        "# Разбивка статей на секции\n",
        "# придется немного подождать, так как на парсинг 100 статей требуется около минуты\n",
        "wikipedia_sections = []\n",
        "for title in titles:\n",
        "    wikipedia_sections.extend(all_subsections_from_title(title))\n",
        "    time.sleep(3)  # Добавляем задержку в 3 секунды после обработки каждой статьи\n",
        "print(f\"Найдено {len(wikipedia_sections)} секций на {len(titles)} страницах\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4up_BckM3oc2"
      },
      "source": [
        "### Очистка текста (теги ссылок, пробелы и короткие секции)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdxev4SjyDwr",
        "outputId": "2f8b7a1e-ed57-4786-b6df-4dbe83a0cd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отфильтровано 91 секций, осталось 887 секций.\n"
          ]
        }
      ],
      "source": [
        "# learing_text\n",
        "# Очистка текста секции от ссылок <ref>xyz</ref>, начальных и конечных пробелов\n",
        "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
        "    titles, text = section\n",
        "    # Удаляем ссылки\n",
        "    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
        "    # Удаляем пробелы вначале и конце\n",
        "    text = text.strip()\n",
        "    return (titles, text)\n",
        "\n",
        "# Применим функцию очистки ко всем секциям с помощью генератора списков\n",
        "wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n",
        "\n",
        "# Отфильтруем короткие и пустые секции\n",
        "def keep_section(section: tuple[list[str], str]) -> bool:\n",
        "    \"\"\"Возвращает значение True, если раздел должен быть сохранен, в противном случае значение False.\"\"\"\n",
        "    titles, text = section\n",
        "    # Фильтруем по произвольной длине, можно выбрать и другое значение\n",
        "    if len(text) < 16:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "original_num_sections = len(wikipedia_sections)\n",
        "wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
        "print(f\"Отфильтровано {original_num_sections-len(wikipedia_sections)} секций, осталось {len(wikipedia_sections)} секций.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDjkQXDj5M_d"
      },
      "source": [
        "Для наглядности выведем 5 секций, заголовок и текст (100 первых символов) каждой секции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m2kAKocO5N7X",
        "outputId": "2a97f0d5-6c5c-4eda-9d85-7a5deb3e9510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Послеоперационные активаторы', 'Ссылки']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\n* [https://www.nose-fit.com www.nose-fit.com]\\n* https://www.sciencedirect.com/science/article/abs...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Категория:Медицинское страхование']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Родственные проекты}}\\n{{Основная статья}}\\n\\n[[Категория:Социальное страхование]]\\n[[Категория:Медици...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Демаркационная линия (медицина)']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'<noinclude>{{к улучшению|2022-08-14}}\\n</noinclude>Демаркацио́нная линия (от лат. demarcatio\\xa0— отгран...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Демаркационная линия (медицина)', 'Примечания']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\n{{примечания}}\\n\\n\\n{{нет ссылок|дата=2022-02-24}}\\n\\n\\n[[Категория:Некроз]]\\n[[Категория:Физиология чел...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Категория:Доказательная медицина']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Родственные проекты}}\\n{{Основная статья}}\\n\\n[[Категория:Медицина]]...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{значения|Диализ (значения)}}\\n{{нет источников|дата=2021-05-10}}\\n[[Файл:Dializa-02-2021.jpg|мини|ап...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Основное']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\nПочки играют важную роль в поддержании здоровья. Когда человек здоров, почки поддерживают внутрен...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Принцип']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\nДиализ работает на принципах [[Диффузия|диффузии]] растворённых веществ и ультрафильтрации жидкос...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Типы']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\nСуществует три основных и два вторичных типа диализа: гемодиализ (первичный), перитонеальный диал...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Типы', 'Гемодиализ']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\n{{Основная статья|...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Типы', 'Перитонеальный диализ']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\n{{falseredirect|...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Типы', 'Кишечный диализ']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\n{{Основная статья|...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Показания']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\nРешение о начале диализа или гемофильтрации у пациентов с почечной недостаточностью зависит от не...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Показания', 'Острые показания']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\nПоказания к диализу у пациента с острым повреждением почек резюмируются мнемоникой гласных «AEIO...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Показания', 'Хронические признаки']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\nХронический диализ может быть показан при наличии у пациента симптоматической почечной недостато...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Диализируемые вещества', 'Характеристики']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\nПоддающиеся диализу вещества\\xa0— вещества, удаляемые диализом,\\xa0— обладают следующими свойствами:\\n\\n...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Диализируемые вещества', 'Вещества']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\n* [[Этиленгликоль]]\\n* [[Прокаинамид]]\\n* [[Метанол]]\\n* [[Изопропанол|Изопропиловый спирт]]\\n* [[Ба...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Детский диализ']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'==\\nЗа последние 20 лет дети получили значительные улучшения как в технологии, так и в клиническом ве...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Диализ в разных странах', 'В Соединённом Королевстве']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\nНациональная служба здравоохранения обеспечивает диализ в Соединённом Королевстве. В Англии услу...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Почечный диализ', 'Диализ в разных странах', 'В Соединённых Штатах']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'===\\nС 1972\\xa0года Соединённые Штаты покрывают стоимость диализа и трансплантации для всех граждан. К 2...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for ws in wikipedia_sections[10:30]:\n",
        "    print(ws[0])\n",
        "    display(ws[1][:100] + \"...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97t-_GMQLCZq"
      },
      "source": [
        "### Фрагментация документов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIT1i3yfLDHW"
      },
      "source": [
        "Поскольку chatGPT может одновременно считывать только ограниченный объем токенов, нам необходимо разделить каждый документ на фрагменты (части).\n",
        "\n",
        "Далее мы рекурсивно разделим длинные разделы на более мелкие. Идеального рецепта разделения текста на разделы не существует.\n",
        "\n",
        "Однако, можно сделать следующие предположения:\n",
        "\n",
        "* Более длинные разделы могут быть лучше для вопросов, требующих большего контекста.\n",
        "* Более длинные разделы могут быть хуже для поиска, поскольку в них может быть больше запутанных тем.\n",
        "* Более короткие разделы лучше подходят для снижения затрат, которые пропорциональны количеству токенов.\n",
        "* Более короткие разделы позволяют извлекать больше разделов для запроса, что может помочь с полнотой данных.\n",
        "* Перекрывающиеся разделы могут помочь предотвратить обрезание ответов по смыслу границами разделов.\n",
        "\n",
        "Учитывая все выше сказанное, мы будем использовать простой подход и ограничим количество разделов до 1600 токенов в каждом, рекурсивно сокращая вдвое любые слишком длинные разделы. Во избежание сокращения в середине полезных предложений, мы будем разделять секции на части по границам абзацев."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up9rkSUVySMr"
      },
      "outputs": [],
      "source": [
        "# Document_fragmentation\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"  # имеет значение только в той мере, в какой он выбирает, какой токенизатор использовать\n",
        "# Явно указываем токенизатор\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "# Функция подсчета токенов\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция разделения строк\n",
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    \"\"\"Разделяет строку надвое с помощью разделителя (delimiter), пытаясь сбалансировать токены с каждой стороны.\"\"\"\n",
        "\n",
        "    # Делим строку на части по разделителю, по умолчанию \\n - перенос строки\n",
        "    chunks = string.split(delimiter)\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  # разделитель не найден\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  # нет необходимости искать промежуточную точку\n",
        "    else:\n",
        "        # Считаем токены\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        # Предварительное разделение по середине числа токенов\n",
        "        best_diff = halfway\n",
        "        # В цикле ищем какой из разделителей, будет ближе всего к best_diff\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        # Возвращаем левую и правую часть оптимально разделенной строки\n",
        "        return [left, right]\n",
        "\n",
        "\n",
        "# Функция обрезает строку до максимально разрешенного числа токенов\n",
        "def truncated_string(\n",
        "    string: str, # строка\n",
        "    model: str, # модель\n",
        "    max_tokens: int, # максимальное число разрешенных токенов\n",
        "    print_warning: bool = True, # флаг вывода предупреждения\n",
        ") -> str:\n",
        "    \"\"\"Обрезка строки до максимально разрешенного числа токенов.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    # Обрезаем строку и декодируем обратно\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
        "    if print_warning and len(encoded_string) > max_tokens:\n",
        "        print(f\"Предупреждение: Строка обрезана с {len(encoded_string)} токенов до {max_tokens} токенов.\")\n",
        "    # Усеченная строка\n",
        "    return truncated_string\n",
        "\n",
        "# Функция делит секции статьи на части по максимальному числу токенов\n",
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], # секции\n",
        "    max_tokens: int = 1000, # максимальное число токенов\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    max_recursion: int = 5, # максимальное число рекурсий\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Разделяет секции на список из частей секций, в каждой части не более max_tokens.\n",
        "    Каждая часть представляет собой кортеж родительских заголовков [H1, H2, ...] и текста (str).\n",
        "    \"\"\"\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    # Если длина соответствует допустимой, то вернет строку\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    # если в результате рекурсия не удалось разделить строку, то просто усечем ее по числу токенов\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    # иначе разделим пополам и выполним рекурсию\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]: # Пробуем использовать разделители от большего к меньшему (разрыв, абзац, точка)\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                # если какая-либо половина пуста, повторяем попытку с более простым разделителем\n",
        "                continue\n",
        "            else:\n",
        "                # применим рекурсию на каждой половине\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1, # уменьшаем максимальное число рекурсий\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    # иначе никакого разделения найдено не было, поэтому просто обрезаем строку (должно быть очень редко)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dM_AWecyXbh",
        "outputId": "1d0ddc4e-85d4-47fd-f685-e3a5509fb96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "887 секций Википедии поделены на 912 строк.\n"
          ]
        }
      ],
      "source": [
        "# Делим секции на части\n",
        "MAX_TOKENS = 2000\n",
        "wikipedia_strings = []\n",
        "for section in wikipedia_sections:\n",
        "    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "\n",
        "print(f\"{len(wikipedia_sections)} секций Википедии поделены на {len(wikipedia_strings)} строк.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXQ1mrpUyeHV",
        "outputId": "94863265-b2fa-40eb-d983-879a75d2bd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Женская больница Мулаго\n",
            "\n",
            "Обзор\n",
            "\n",
            "==\n",
            "Строительство больницы началось в апреле 2013 года, а ввод в эксплуатацию изначально ожидался во второй половине 2016 года. После задержек строительство было завершено в июле 2018 года.\n",
            "\n",
            "Женская больница Мулаго — это [[Реферативная практика (медицина)|реферативное]] медицинское учреждение, женское отделение Национальной больницы Мулаго. В его состав входят дородовые клиники, родильные отделения, операционные, палаты послеродового наблюдения и послеродовые отделения. Больница обслуживает пациентов акушерско-гинекологического профиля. В больнице имеется онкологическое отделение, предназначенное для пациентов с гинекологическими онкологическими заболеваниями, включая рак яичников, рак фаллопиевых труб, рак матки, рак эндометрия, рак шейки матки, рак влагалища и злокачественные новообразования вульвы. \n",
            "\n",
            "В больнице будут оборудованные по последнему слову техники отделения для новорожденных, отделения для недоношенных детей, отделение интенсивной терапии для новорожденных и отдельное крыло на 60 коек для будущих мам, только что родивших и частных гинекологических пациентов. Больница будет заниматься пренатальными и гинекологическими случаями высокого риска. \n",
            "\n",
            "В больнице имеется отделение, специализирующееся на профилактике, лечении и реабилитации акушерских свищей. Здесь также находится первая в стране государственная клиника по лечению бесплодия.\n"
          ]
        }
      ],
      "source": [
        "# Напечатаем пример строки\n",
        "print(wikipedia_strings[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB_0hDCcN9aM"
      },
      "source": [
        "### Токенизация и сохранение результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngV5CmVuOBmb"
      },
      "source": [
        "Теперь, когда мы разделили нашу базу знаний на более короткие автономные строки, мы можем вычислять эмбединги для каждой строки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Zg31ag2UxX",
        "outputId": "d542eb72-968d-4c39-ffa4-31be7194dd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введите VseGPT API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# Tokenization_save\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import pandas as pd\n",
        "import getpass\n",
        "\n",
        "# Модель эмбеддингов\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "# Получаем ключ API от пользователя\n",
        "os.environ[\"VSEGPT_API_KEY\"] = getpass.getpass(\"Введите VseGPT API Key:\")\n",
        "\n",
        "# Создаем клиент OpenAI с настройкой на использование API VseGPT\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"VSEGPT_API_KEY\"),\n",
        "    base_url=\"https://api.vsegpt.ru/v1\",\n",
        ")\n",
        "\n",
        "# Функция для вычисления эмбеддингов строки\n",
        "def get_embedding(text, model=EMBEDDING_MODEL):\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp4psjkOPCIZ"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"text\": wikipedia_strings[:15]})\n",
        "\n",
        "df['embedding'] = df.text.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "\n",
        "SAVE_PATH = \"./medicine_knowledge_2022.csv\"\n",
        "# Сохранение результата\n",
        "df.to_csv(SAVE_PATH, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpvdrW_vhZiM"
      },
      "source": [
        "Сохраню базу знаний в CSV-файле.\n",
        "\n",
        "Для больших наборов данных необходимо использовать векторную базу данных, которая будет более производительной."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "UfmUo3ujPZE6",
        "outputId": "ef976424-43f4-4b82-9ad0-7f465c577944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Женская больница Мулаго\\n\\n{{Универсальная кар...   \n",
              "1  Женская больница Мулаго\\n\\nРасположение\\n\\n==\\...   \n",
              "2  Женская больница Мулаго\\n\\nОбзор\\n\\n==\\nСтроит...   \n",
              "3  Женская больница Мулаго\\n\\nРаспределение коек\\...   \n",
              "4  Женская больница Мулаго\\n\\nРуководство\\n\\n==\\n...   \n",
              "5  Женская больница Мулаго\\n\\nСм. также\\n\\n==\\n\\n...   \n",
              "6  Женская больница Мулаго\\n\\nПримечания\\n\\n==\\n<...   \n",
              "7  Женская больница Мулаго\\n\\nСсылки\\n\\n==\\n\\n* [...   \n",
              "8  Послеоперационные активаторы\\n\\n<noinclude>{{к...   \n",
              "9  Послеоперационные активаторы\\n\\nПримечания\\n\\n...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.02458954229950905, 0.012538427487015724, -...  \n",
              "1  [-0.005425150506198406, 0.017862308770418167, ...  \n",
              "2  [-0.01604926772415638, 0.011421728879213333, -...  \n",
              "3  [-0.013167863711714745, 0.009832487441599369, ...  \n",
              "4  [-0.026457738131284714, -0.0018055977998301387...  \n",
              "5  [-0.01516191940754652, 0.00015063137107063085,...  \n",
              "6  [-0.013714994303882122, 0.007285228464752436, ...  \n",
              "7  [-0.016681814566254616, 0.006670073606073856, ...  \n",
              "8  [-0.0186057910323143, 0.0111607126891613, -0.0...  \n",
              "9  [-0.022903330624103546, 0.019568033516407013, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-500c6b31-8323-4f6c-bbd0-82f6c1ddf050\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Женская больница Мулаго\\n\\n{{Универсальная кар...</td>\n",
              "      <td>[-0.02458954229950905, 0.012538427487015724, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Женская больница Мулаго\\n\\nРасположение\\n\\n==\\...</td>\n",
              "      <td>[-0.005425150506198406, 0.017862308770418167, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Женская больница Мулаго\\n\\nОбзор\\n\\n==\\nСтроит...</td>\n",
              "      <td>[-0.01604926772415638, 0.011421728879213333, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Женская больница Мулаго\\n\\nРаспределение коек\\...</td>\n",
              "      <td>[-0.013167863711714745, 0.009832487441599369, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Женская больница Мулаго\\n\\nРуководство\\n\\n==\\n...</td>\n",
              "      <td>[-0.026457738131284714, -0.0018055977998301387...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Женская больница Мулаго\\n\\nСм. также\\n\\n==\\n\\n...</td>\n",
              "      <td>[-0.01516191940754652, 0.00015063137107063085,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Женская больница Мулаго\\n\\nПримечания\\n\\n==\\n&lt;...</td>\n",
              "      <td>[-0.013714994303882122, 0.007285228464752436, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Женская больница Мулаго\\n\\nСсылки\\n\\n==\\n\\n* [...</td>\n",
              "      <td>[-0.016681814566254616, 0.006670073606073856, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Послеоперационные активаторы\\n\\n&lt;noinclude&gt;{{к...</td>\n",
              "      <td>[-0.0186057910323143, 0.0111607126891613, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Послеоперационные активаторы\\n\\nПримечания\\n\\n...</td>\n",
              "      <td>[-0.022903330624103546, 0.019568033516407013, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-500c6b31-8323-4f6c-bbd0-82f6c1ddf050')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-500c6b31-8323-4f6c-bbd0-82f6c1ddf050 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-500c6b31-8323-4f6c-bbd0-82f6c1ddf050');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a704b99c-360f-4155-a404-aa29caa02dff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a704b99c-360f-4155-a404-aa29caa02dff')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a704b99c-360f-4155-a404-aa29caa02dff button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"\\u041f\\u043e\\u0441\\u043b\\u0435\\u043e\\u043f\\u0435\\u0440\\u0430\\u0446\\u0438\\u043e\\u043d\\u043d\\u044b\\u0435 \\u0430\\u043a\\u0442\\u0438\\u0432\\u0430\\u0442\\u043e\\u0440\\u044b\\n\\n\\u041f\\u0440\\u0438\\u043c\\u0435\\u0447\\u0430\\u043d\\u0438\\u044f\\n\\n==\\n# Yeow, V.K., Chen, P.K., Chen, Y.R. et al, The use of nasal splints in the primary management of unilateral cleft nasal deformity. Plast Reconstr Surg. 1999;103:1347.\\n# Markus, A.F., Delaire, J. Functional closure of cleft lip. Br J Oral Maxillofac Surg. 1993;31:281.\\n# Talmant, J.C., Lumineau, J.P., Rousteau, G. Prise en charge des fentes labiomaxillo-Palatines dans l'\\u00e9quipe du docteur Talmant \\u00e0 Nantes. Ann Chir Plast Esthet. 2002;47:116.\\n# Tan, O., Atik, B., Vayvada, H. A new custom-made nostril retainer: The rubber of infusion set. Plast Reconstr Surg. 2006;117:1053.\\n# \\u00d6zyazgan, I., Eskita\\u015f\\u00e7io\\u011flu, A. New reshaped nostril retainer. Plast Reconstr Surg. 2000;105:804.\\n{{\\u043f\\u0440\\u0438\\u043c\\u0435\\u0447\\u0430\\u043d\\u0438\\u044f}}\",\n          \"\\u041a\\u0430\\u0442\\u0435\\u0433\\u043e\\u0440\\u0438\\u044f:\\u041c\\u0435\\u0434\\u0438\\u0446\\u0438\\u043d\\u0441\\u043a\\u043e\\u0435 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435\\n\\n{{\\u0420\\u043e\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u044b\\u0435 \\u043f\\u0440\\u043e\\u0435\\u043a\\u0442\\u044b}}\\n{{\\u041e\\u0441\\u043d\\u043e\\u0432\\u043d\\u0430\\u044f \\u0441\\u0442\\u0430\\u0442\\u044c\\u044f}}\\n\\n[[\\u041a\\u0430\\u0442\\u0435\\u0433\\u043e\\u0440\\u0438\\u044f:\\u0421\\u043e\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u043e\\u0435 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435]]\\n[[\\u041a\\u0430\\u0442\\u0435\\u0433\\u043e\\u0440\\u0438\\u044f:\\u041c\\u0435\\u0434\\u0438\\u0446\\u0438\\u043d\\u0430]]\",\n          \"\\u0416\\u0435\\u043d\\u0441\\u043a\\u0430\\u044f \\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u0430 \\u041c\\u0443\\u043b\\u0430\\u0433\\u043e\\n\\n{{\\u0423\\u043d\\u0438\\u0432\\u0435\\u0440\\u0441\\u0430\\u043b\\u044c\\u043d\\u0430\\u044f \\u043a\\u0430\\u0440\\u0442\\u043e\\u0447\\u043a\\u0430}}\\n\\n'''\\u0416\\u0435\\u043d\\u0441\\u043a\\u0430\\u044f \\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u0430 \\u041c\\u0443\\u043b\\u0430\\u0433\\u043e''' ({{Lang-en|Mulago Women's Referral Hospital}}) \\u2014 \\u0447\\u0430\\u0441\\u0442\\u044c \\u041d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0440\\u0435\\u0444\\u0435\\u0440\\u0430\\u0442\\u0438\\u0432\\u043d\\u043e\\u0439 \\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u044b \\u041c\\u0443\\u043b\\u0430\\u0433\\u043e, \\u043a\\u0440\\u0443\\u043f\\u043d\\u0435\\u0439\\u0448\\u0435\\u0439 \\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u044b \\u0432 \\u0423\\u0433\\u0430\\u043d\\u0434\\u0435 \\u043f\\u0440\\u0438 \\u041c\\u0435\\u0434\\u0438\\u0446\\u0438\\u043d\\u0441\\u043a\\u043e\\u043c \\u043a\\u043e\\u043b\\u043b\\u0435\\u0434\\u0436\\u0435 [[\\u0423\\u043d\\u0438\\u0432\\u0435\\u0440\\u0441\\u0438\\u0442\\u0435\\u0442 \\u041c\\u0430\\u043a\\u0435\\u0440\\u0435\\u0440\\u0435|\\u0423\\u043d\\u0438\\u0432\\u0435\\u0440\\u0441\\u0438\\u0442\\u0435\\u0442\\u0430 \\u041c\\u0430\\u043a\\u0435\\u0440\\u0435\\u0440\\u0435]]. \\u041e\\u0444\\u0438\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u043e\\u0435 \\u043d\\u0430\\u0437\\u0432\\u0430\\u043d\\u0438\\u0435 \\u2014 \\u00ab'''\\u0421\\u043f\\u0435\\u0446\\u0438\\u0430\\u043b\\u0438\\u0437\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u043d\\u0430\\u044f \\u0436\\u0435\\u043d\\u0441\\u043a\\u0430\\u044f \\u0438 \\u043d\\u0435\\u043e\\u043d\\u0430\\u0442\\u0430\\u043b\\u044c\\u043d\\u0430\\u044f \\u0431\\u043e\\u043b\\u044c\\u043d\\u0438\\u0446\\u0430 \\u041c\\u0443\\u043b\\u0430\\u0433\\u043e\\u00bb''' ({{Lang-en|Mulago Specialised Women and Neonatal Hospital}}).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgWBf8Tu14AK"
      },
      "source": [
        "Подгружаю данные из CSV-файла и преобразуем строковые представления списков в настоящие списки, в столбце embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ooaPwor1vg2"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "embeddings_path = \"./medicine_knowledge_2022.csv\"\n",
        "\n",
        "df = pd.read_csv(embeddings_path)\n",
        "\n",
        "# Конвертируем наши эмбединги из строк в списки\n",
        "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PsjSJsQ2jd0"
      },
      "source": [
        "# **Метод Search**\n",
        "Далее, определим функцию поиска, которая:\n",
        "\n",
        "* Принимает пользовательский запрос и DataFrame со столбцами `text` и `embedding`;\n",
        "* Токенизирует пользовательский запрос с помощью OpenAI API (для этого используется токенизатор `text-embedding-ada-002`);\n",
        "* Использует косинусное расстояние для определения схожести между токенизированым пользовательским запросом и эмбендингами в DataFrame для ранжирования текстов по схожести или релевантности;\n",
        "* Возвращает два списка:\n",
        "  * N лучших текстов, ранжированных по релевантности;\n",
        "  * Их соответствующие оценки релевантности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMeg4MntcZn1"
      },
      "outputs": [],
      "source": [
        "from scipy import spatial  # вычисляет сходство векторов\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "# Функция поиска\n",
        "def strings_ranked_by_relatedness(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), # функция схожести, косинусное расстояние\n",
        "    top_n: int = 100 # выбор лучших n-результатов\n",
        ") -> tuple[list[str], list[float]]: # Функция возвращает кортеж двух списков, первый содержит строки, второй - числа с плавающей запятой\n",
        "    \"\"\"Возвращает строки и схожести, отсортированные от большего к меньшему\"\"\"\n",
        "\n",
        "    # Отправляем в OpenAI API пользовательский запрос для токенизации\n",
        "    query_embedding_response = client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=query,\n",
        "    )\n",
        "\n",
        "    # Получен токенизированный пользовательский запрос\n",
        "    query_embedding = query_embedding_response.data[0].embedding\n",
        "\n",
        "    # Сравниваем пользовательский запрос с каждой токенизированной строкой DataFrame\n",
        "    strings_and_relatednesses = [\n",
        "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
        "        for i, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Сортируем по убыванию схожести полученный список\n",
        "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Преобразовываем наш список в кортеж из списков\n",
        "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
        "\n",
        "    # Возвращаем n лучших результатов\n",
        "    return strings[:top_n], relatednesses[:top_n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxDawX2t6bh0"
      },
      "source": [
        "# **Метод Ask**\n",
        "\n",
        "С помощью функции поиска, описанной выше, мы теперь можем автоматически извлекать необходимые сведения из DataFrame и вставлять их в сообщения для chatGPT.\n",
        "\n",
        "Ниже мы определяем функцию ask, которая:\n",
        "\n",
        "* Принимает запрос пользователя\n",
        "* Ищет в базе знаний текст релевантный запросу\n",
        "* Вставляет этот текст в сообщение для GPT\n",
        "* Отправляет сообщение в GPT\n",
        "* Возвращает ответ GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2HV4aSc6GrO",
        "outputId": "1dafee4e-1411-4edf-b888-8d63db40eb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# устанавливаем библиотеку\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xbd9Xhl6J-N"
      },
      "outputs": [],
      "source": [
        "# Ask_method\n",
        "# с этой функцией мы уже знакомы\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке для заданной модели\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция формирования запроса к chatGPT по пользовательскому вопросу и базе знаний\n",
        "def query_message(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str, # модель\n",
        "    token_budget: int # ограничение на число отсылаемых токенов в модель\n",
        ") -> str:\n",
        "    \"\"\"Возвращает сообщение для GPT с соответствующими исходными текстами, извлеченными из фрейма данных (базы знаний).\"\"\"\n",
        "    strings, relatednesses = strings_ranked_by_relatedness(query, df) # функция ранжирования базы знаний по пользовательскому запросу\n",
        "    # Шаблон инструкции для chatGPT\n",
        "    message = 'Используйте приведенные ниже статьи о Медицине, чтобы ответить на следующий вопрос. Если ответ не найден в статьях, напишите \"Я не смог найти ответ\".'\n",
        "    # Шаблон для вопроса\n",
        "    question = f\"\\n\\nQuestion: {query}\"\n",
        "\n",
        "    # Добавляем к сообщению для chatGPT релевантные строки из базы знаний, пока не выйдем за допустимое число токенов\n",
        "    for string in strings:\n",
        "        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
        "        if (num_tokens(message + next_article + question, model=model) > token_budget):\n",
        "            break\n",
        "        else:\n",
        "            message += next_article\n",
        "    return message + question\n",
        "\n",
        "\n",
        "def ask(\n",
        "    query: str, # пользовательский запрос\n",
        "    df: pd.DataFrame = df, # DataFrame со столбцами text и embedding (база знаний)\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    token_budget: int = 4096 - 1000, # ограничение на число отсылаемых токенов в модель\n",
        "    print_message: bool = False, # нужно ли выводить сообщение перед отправкой\n",
        ") -> str:\n",
        "    \"\"\"Отвечает на вопрос, используя GPT и базу знаний.\"\"\"\n",
        "    # Формируем сообщение к chatGPT (функция выше)\n",
        "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
        "    # Если параметр True, то выводим сообщение\n",
        "    if print_message:\n",
        "        print(message)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Ты большой знаток медицины, и если нет информации в базе данных, ты ответишь сам.\"},\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "    ]\n",
        "    response = client.chat.completions.create (\n",
        "    model = model,\n",
        "    messages = messages,\n",
        "    temperature = 0 # гиперпараметр степени случайности при генерации текста. Влияет на то, как модель выбирает следующее слово в последовательности.\n",
        "    )\n",
        "    response_message = response.choices[0].message.content\n",
        "    return response_message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k0ZZ5FS7OAx"
      },
      "source": [
        "# Создаю Телеграмм бота\n",
        "\n",
        "Уклон бота будет поиск информации по медецине"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UvDwtfx6NQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c1ab91-3d51-49ed-d23f-b335f5b07218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/698.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/698.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.2/698.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Установка библиотек\n",
        "!pip install aiogram -q\n",
        "!pip install aiosqlite -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC2hlXXxefxJ"
      },
      "outputs": [],
      "source": [
        "# Установим библиотеку nest_asyncio\n",
        "!pip install nest_asyncio -q\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trfjheRH_k4E"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотек\n",
        "import asyncio\n",
        "import logging\n",
        "import aiosqlite\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters.command import Command\n",
        "from aiogram import types\n",
        "from aiogram.utils.keyboard import InlineKeyboardBuilder, ReplyKeyboardBuilder\n",
        "from aiogram import F\n",
        "from aiogram.types import ReplyKeyboardMarkup, KeyboardButton"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Включаем логирование, чтобы не пропустить важные сообщения\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "# Ваш токен бота\n",
        "API_TOKEN = '7566236365:AAGHsZRfG_QThq_pMAnbp39_S6GzqzkKN9M'\n",
        "\n",
        "# Создаем объекты бота и диспетчера\n",
        "bot = Bot(token=API_TOKEN)\n",
        "dp = Dispatcher()\n",
        "\n",
        "# Хэндлер на команду /start\n",
        "@dp.message(Command(\"start\"))\n",
        "async def cmd_start(message: types.Message):\n",
        "       builder = ReplyKeyboardBuilder()\n",
        "       builder.add(types.KeyboardButton(text=\"Задать вопрос\"))\n",
        "       await message.answer(\n",
        "           \"Привет! Я бот, знающий информацию о медицине. В будущем я смогу давать рекомендации по твоему здоровью, а пока ты можешь у меня спросить всё, что касается медицины. \"\n",
        "           \"Чтобы получить информацию по взаимодействию с ботом, введите /help.\",\n",
        "           reply_markup=builder.as_markup(resize_keyboard=True)\n",
        "       )\n",
        "\n",
        "@dp.message(Command('help'))\n",
        "async def help_me(message: types.Message):\n",
        "       await message.answer(f'Тематика бота: медицина')\n",
        "       await message.answer(f'Число записей в базе знаний: {df.shape[0]}')\n",
        "       await message.answer(f'Пример запроса: Расскажи о направлениях и областях в медицине')\n",
        "\n",
        "@dp.message()\n",
        "async def handle_message(message: types.Message):\n",
        "       if message.text == \"Задать вопрос\":\n",
        "           await ask_question_prompt(message)\n",
        "       else:\n",
        "           await ask_question(message)\n",
        "\n",
        "async def ask_question_prompt(message: types.Message):\n",
        "       await message.answer(\"Задавайте вопрос, я посмотрю, есть ли в моей базе знаний ответы.\")\n",
        "\n",
        "async def ask_question(message: types.Message):\n",
        "       user_query = message.text\n",
        "       try:\n",
        "           await message.answer(\"Один момент, поиск информации...\")\n",
        "           answer = ask(user_query)\n",
        "           await message.answer(answer)\n",
        "       except Exception as e:\n",
        "           await message.answer(f\"Произошла ошибка: {str(e)}\")\n",
        "\n",
        "# Основной цикл программы\n",
        "async def main():\n",
        "       await dp.start_polling(bot)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "       asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq9XQp-G0wo2",
        "outputId": "e03f4bd3-f4d5-4aae-8935-f9d37863862d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}